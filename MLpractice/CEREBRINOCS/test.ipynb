{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subhraj07/Machine_Learning_Models/blob/master/MLpractice/CEREBRINOCS/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLJ8osn6FzOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "outputId": "05b9adc2-9711-4f39-ce60-7365b7a478bb"
      },
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (4,772 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 130963 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUdGUH8sF7K_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "32c59ac8-7c63-4f1b-8fec-2a3bd8a73285"
      },
      "source": [
        "!pip install pytesseract"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/40/3f72d13d0f347bf688ff189b6d6bb369125c0bed9ed4b15e7f20c65123a8/pytesseract-0.2.7.tar.gz (169kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->pytesseract) (0.46)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/4a/30/998e01b892300ba0ccce7b806b6e889794605a384dac81a49a\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H35Sf9X6OYjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip '/content/drive/My Drive/Vehicle_Licenseplate_Detection/Datasets/train20X20.zip'\n",
        "# import shutil\n",
        "# shutil.move(\"/content/train20X20\", \"/content/drive/My Drive/Vehicle_Licenseplate_Detection/Datasets/\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6k4eQopNcK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "177b270d-242e-43f1-9b24-896aebb18a5b"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.externals import joblib\n",
        "from skimage.io import imread\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "letters = [\n",
        "            '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D',\n",
        "            'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T',\n",
        "            'U', 'V', 'W', 'X', 'Y', 'Z'\n",
        "        ]\n",
        "\n",
        "def read_training_data(training_directory):\n",
        "    image_data = []\n",
        "    target_data = []\n",
        "    for each_letter in letters:\n",
        "        for each in range(10):\n",
        "            image_path = os.path.join(training_directory, each_letter, each_letter + '_' + str(each) + '.jpg')\n",
        "            # read each image of each character\n",
        "            img_details = imread(image_path, as_gray=True)\n",
        "            # converts each character image to binary image\n",
        "            binary_image = img_details < threshold_otsu(img_details)\n",
        "            # the 2D array of each image is flattened because the machine learning\n",
        "            # classifier requires that each sample is a 1D array\n",
        "            # therefore the 20*20 image becomes 1*400\n",
        "            # in machine learning terms that's 400 features with each pixel\n",
        "            # representing a feature\n",
        "            flat_bin_image = binary_image.reshape(-1)\n",
        "            image_data.append(flat_bin_image)\n",
        "            target_data.append(each_letter)\n",
        "\n",
        "    return (np.array(image_data), np.array(target_data))\n",
        "  \n",
        "training_dataset_dir = '/content/drive/My Drive/Vehicle_Licenseplate_Detection/Datasets/train20X20'\n",
        "image_data, target_data = read_training_data(training_dataset_dir)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez9MM3ADGCBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.models import Sequential  # To initialise the nn as a sequence of layers\n",
        "# from keras.layers import Convolution2D  # To make the convolution layer for 2D images\n",
        "# from keras.layers import MaxPooling2D  #\n",
        "# from keras.layers import Flatten\n",
        "# from keras.layers import Dense\n",
        "# from keras.layers import Dropout\n",
        "# from keras.callbacks import CSVLogger\n",
        "# from keras.optimizers import RMSprop\n",
        "\n",
        "# # Initialising the CNN\n",
        "# classifier = Sequential()\n",
        "\n",
        "# # Step 1 - Convolution\n",
        "# classifier.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "# # Step 2 - Pooling\n",
        "# classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# # Step 1 - Convolution\n",
        "# classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "# # Step 2 - Pooling\n",
        "# classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# # Step 3 - Flattening\n",
        "# classifier.add(Flatten())\n",
        "\n",
        "# classifier.add(Dense(128, activation='relu'))\n",
        "# classifier.add(Dropout((0.07)))\n",
        "# classifier.add(Dense(36, activation='softmax'))\n",
        "\n",
        "# csv = CSVLogger(\"/content/drive/My Drive/Vehicle_Licenseplate_Detection/Datasets/VLPR/Metrics_Evaluation/epochs2.log\")\n",
        "\n",
        "# # Compiling the CNN\n",
        "# classifier.compile(optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.005), loss='categorical_crossentropy',\n",
        "#                    metrics=['accuracy'])\n",
        "\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "# train_set = train_datagen.flow_from_directory('Train', target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# test_set = test_datagen.flow_from_directory('Test', target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# classifier.fit_generator(train_set, steps_per_epoch=47605, epochs=5, validation_data=test_set, validation_steps=1292,\n",
        "#                          callbacks=[csv])\n",
        "\n",
        "# classifier.save('/content/drive/My Drive/Vehicle_Licenseplate_Detection/Datasets/VLPR/Metrics_Evaluation/char-reg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBIFEP7hTgP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "# module level variables ##########################################################################\n",
        "GAUSSIAN_SMOOTH_FILTER_SIZE = (5, 5)\n",
        "ADAPTIVE_THRESH_BLOCK_SIZE = 19\n",
        "ADAPTIVE_THRESH_WEIGHT = 9\n",
        "\n",
        "###################################################################################################\n",
        "def preprocess(imgOriginal):\n",
        "    imgGrayscale = extractValue(imgOriginal) # We get the gray scale of the image.\n",
        "    #imgGrayscale = cv2.equalizeHist(imgGrayscale)\n",
        "    imgMaxContrastGrayscale = maximizeContrast(imgGrayscale) # contrast is the difference between light and dark in an image. High contrast images will have bright highlights and dark shadows,bold colours, and show texture in the subject. Low contrast images will have a narrow range of tones and might therefore feel flat or dull\n",
        "    height,width = imgGrayscale.shape\n",
        "    imgBlurred = np.zeros((height, width, 1), np.uint8)\n",
        "\n",
        "    imgBlurred = cv2.GaussianBlur(imgMaxContrastGrayscale, GAUSSIAN_SMOOTH_FILTER_SIZE, 0) # 2nd parameter is (height,width) of Gaussian kernel,3rd parameter is sigmaX,4th parameter is sigmaY(as not specified it is made same as sigmaX).\n",
        "    \n",
        "    imgThresh = cv2.adaptiveThreshold(imgBlurred, 255.0, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, ADAPTIVE_THRESH_BLOCK_SIZE, ADAPTIVE_THRESH_WEIGHT)\n",
        "    \n",
        "    return imgGrayscale, imgThresh\n",
        "\n",
        "###################################################################################################\n",
        "def extractValue(imgOriginal):\n",
        "    height, width, numChannels = imgOriginal.shape\n",
        "\n",
        "    imgHSV = np.zeros((height, width, 3), np.uint8)\n",
        "\n",
        "    imgHSV = cv2.cvtColor(imgOriginal, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    imgHue, imgSaturation, imgValue = cv2.split(imgHSV)\n",
        "\n",
        "    return imgValue\n",
        "\n",
        "###################################################################################################\n",
        "def maximizeContrast(imgGrayscale):\n",
        "\n",
        "    height, width = imgGrayscale.shape\n",
        "\n",
        "    imgTopHat = np.zeros((height, width, 1), np.uint8)\n",
        "    imgBlackHat = np.zeros((height, width, 1), np.uint8)\n",
        "\n",
        "    structuringElement = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)) # Same as np.ones((3,3)\n",
        "\n",
        "    imgTopHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_TOPHAT, structuringElement) # It is difference of  input image and Opening of the image\n",
        "    imgBlackHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_BLACKHAT, structuringElement) # it is difference of closing of the input image and input image.\n",
        "\n",
        "    imgGrayscalePlusTopHat = cv2.add(imgGrayscale, imgTopHat)\n",
        "    imgGrayscalePlusTopHatMinusBlackHat = cv2.subtract(imgGrayscalePlusTopHat, imgBlackHat)\n",
        "\n",
        "    return imgGrayscalePlusTopHatMinusBlackHat\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqdS_-xsVlHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "###################################################################################################\n",
        "class PossibleChar:\n",
        "\n",
        "    # constructor #################################################################################\n",
        "    def __init__(self, _contour):\n",
        "        self.contour = _contour\n",
        "\n",
        "        self.boundingRect = cv2.boundingRect(self.contour) # It gives the (x,y,w,h) of a straight rectangle that bounds the contour. It is not sensetive to the rotation of the obejct ,so its area will not be minimum.\n",
        "\n",
        "        [intX, intY, intWidth, intHeight] = self.boundingRect\n",
        "\n",
        "        self.intBoundingRectX = intX\n",
        "        self.intBoundingRectY = intY\n",
        "        self.intBoundingRectWidth = intWidth\n",
        "        self.intBoundingRectHeight = intHeight\n",
        "\n",
        "        self.intBoundingRectArea = self.intBoundingRectWidth * self.intBoundingRectHeight\n",
        "\n",
        "        self.intCenterX = (self.intBoundingRectX + self.intBoundingRectX + self.intBoundingRectWidth) / 2\n",
        "        self.intCenterY = (self.intBoundingRectY + self.intBoundingRectY + self.intBoundingRectHeight) / 2\n",
        "\n",
        "        self.fltDiagonalSize = math.sqrt((self.intBoundingRectWidth ** 2) + (self.intBoundingRectHeight ** 2))\n",
        "\n",
        "        self.fltAspectRatio = float(self.intBoundingRectWidth) / float(self.intBoundingRectHeight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq9wInhmZJhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "###################################################################################################\n",
        "class PossiblePlate:\n",
        "\n",
        "    # constructor #################################################################################\n",
        "    def __init__(self):\n",
        "        self.imgPlate = None\n",
        "        self.imgGrayscale = None\n",
        "        self.imgThresh = None\n",
        "\n",
        "        self.rrLocationOfPlateInScene = None\n",
        "\n",
        "        self.strChars = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36pcSnuPVx8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DetectChars.py\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "# module level variables ##########################################################################\n",
        "        # constants for checkIfPossibleChar, this checks one possible char only (does not compare to another char)\n",
        "MIN_PIXEL_WIDTH = 2\n",
        "MIN_PIXEL_HEIGHT = 8\n",
        "\n",
        "MIN_ASPECT_RATIO = 0.25\n",
        "MAX_ASPECT_RATIO = 1.0\n",
        "\n",
        "MIN_PIXEL_AREA = 80\n",
        "\n",
        "        # constants for comparing two chars\n",
        "MIN_DIAG_SIZE_MULTIPLE_AWAY = 0.3\n",
        "MAX_DIAG_SIZE_MULTIPLE_AWAY = 5.0\n",
        "\n",
        "MAX_CHANGE_IN_AREA = 0.5\n",
        "\n",
        "MAX_CHANGE_IN_WIDTH = 0.8\n",
        "MAX_CHANGE_IN_HEIGHT = 0.2\n",
        "\n",
        "MAX_ANGLE_BETWEEN_CHARS = 12.0\n",
        "\n",
        "        # other constants\n",
        "MIN_NUMBER_OF_MATCHING_CHARS = 3\n",
        "\n",
        "RESIZED_CHAR_IMAGE_WIDTH = 64\n",
        "RESIZED_CHAR_IMAGE_HEIGHT = 64\n",
        "\n",
        "MIN_CONTOUR_AREA = 100\n",
        "model = load_model('/content/drive/My Drive/Vehicle_Licenseplate_Detection/Datasets/char-reg.h5')\n",
        "###################################################################################################\n",
        "def loadCNNClassifier():\n",
        "    model.compile(optimizer = RMSprop(lr=0.001,rho=0.9,epsilon=1e-08,decay=0.005), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return True###################################################################################################\n",
        "def detectCharsInPlates(listOfPossiblePlates):\n",
        "    intPlateCounter = 0\n",
        "    imgContours = None\n",
        "    contours = []\n",
        "\n",
        "    if len(listOfPossiblePlates) == 0:          # if list of possible plates is empty\n",
        "        return listOfPossiblePlates             # return\n",
        "    # end if\n",
        "\n",
        "            # at this point we can be sure the list of possible plates has at least one plate\n",
        "    listOfPossiblePlates_refined = []\n",
        "    for possiblePlate in listOfPossiblePlates:          # for each possible plate, this is a big for loop that takes up most of the function\n",
        "        #possiblePlate.imgPlate = cv2.fastNlMeansDenoisingColored(possiblePlate.imgPlate,None,15,15,7,21)\n",
        "        #possiblePlate.imgPlate = cv2.equalizeHist(possiblePlate.imgPlate)\n",
        "        possiblePlate.imgGrayscale, possiblePlate.imgThresh = preprocess(possiblePlate.imgPlate)     # preprocess to get grayscale and threshold images\n",
        "\n",
        "            \n",
        "        possiblePlate.imgThresh = cv2.resize(possiblePlate.imgThresh, (0, 0), fx = 1.6, fy = 1.6,interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                # threshold again to eliminate any gray areas\n",
        "        thresholdValue, possiblePlate.imgThresh = cv2.threshold(possiblePlate.imgThresh, 0.0, 255.0, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "        # This clears the image more removing all the unknown noise from it.\n",
        "        if showSteps == True: # show steps ###################################################\n",
        "            Image.fromarray(possiblePlate.imgThresh).show()\n",
        "#             input('Press Enter to Continue....')\n",
        "        # end if # show steps #####################################################################\n",
        "\n",
        "                # find all possible chars in the plate,\n",
        "                # this function first finds all contours, then only includes contours that could be chars (without comparison to other chars yet)\n",
        "        listOfPossibleCharsInPlate = findPossibleCharsInPlate(possiblePlate.imgGrayscale, possiblePlate.imgThresh)\n",
        "\n",
        "        if showSteps == True: # show steps ###################################################\n",
        "            height, width, numChannels = possiblePlate.imgPlate.shape\n",
        "            imgContours = np.zeros((height, width, 3), np.uint8)\n",
        "            del contours[:]                                         # clear the contours list\n",
        "\n",
        "            for possibleChar in listOfPossibleCharsInPlate:\n",
        "                contours.append(possibleChar.contour)\n",
        "            # end for\n",
        "\n",
        "            cv2.drawContours(imgContours, contours, -1, SCALAR_WHITE)\n",
        "            #print('These are the possible characters in the plate :')\n",
        "            imgContours = Image.fromarray(imgContours,'RGB')\n",
        "            imgContours.show()\n",
        "#             input('Press Enter to Continue....')\n",
        "        # end if # show steps #####################################################################\n",
        "\n",
        "                # given a list of all possible chars, find groups of matching chars within the plate\n",
        "        listOfListsOfMatchingCharsInPlate = findListOfListsOfMatchingChars(listOfPossibleCharsInPlate)\n",
        "        if (len(listOfListsOfMatchingCharsInPlate) == 0):            # if no groups of matching chars were found in the plate\n",
        "            #print('\\nNo matching characters found:')\n",
        "            if showSteps == True: # show steps ###############################################\n",
        "                print(\"chars found in plate number \" + str(intPlateCounter) + \" = (none), click on any image and press a key to continue . . .\")\n",
        "                intPlateCounter = intPlateCounter + 1\n",
        "\n",
        "                \n",
        "            # end if # show steps #################################################################\n",
        "\n",
        "            possiblePlate.strChars = \"\"\n",
        "            continue                        # go back to top of for loop\n",
        "        # end if\n",
        "\n",
        "        if showSteps == True: # show steps ###################################################\n",
        "            imgContours = np.zeros((height, width, 3), np.uint8)\n",
        "            del contours[:]\n",
        "\n",
        "            for listOfMatchingChars in listOfListsOfMatchingCharsInPlate:\n",
        "                intRandomBlue = random.randint(0, 255)\n",
        "                intRandomGreen = random.randint(0, 255)\n",
        "                intRandomRed = random.randint(0, 255)\n",
        "\n",
        "                for matchingChar in listOfMatchingChars:\n",
        "                    contours.append(matchingChar.contour)\n",
        "                # end for\n",
        "                cv2.drawContours(imgContours, contours, -1, (intRandomBlue, intRandomGreen, intRandomRed))\n",
        "            # end for\n",
        "            imgContours = Image.fromarray(imgContours,'RGB')\n",
        "            imgContours.show()\n",
        "#             input('Press Enter to Continue....')\n",
        "        # end if # show steps #####################################################################\n",
        "\n",
        "        for i in range(0, len(listOfListsOfMatchingCharsInPlate)):                              # within each list of matching chars\n",
        "            listOfListsOfMatchingCharsInPlate[i].sort(key = lambda matchingChar: matchingChar.intCenterX)        # sort chars from left to right\n",
        "            listOfListsOfMatchingCharsInPlate[i] = removeInnerOverlappingChars(listOfListsOfMatchingCharsInPlate[i])              # and remove inner overlapping chars\n",
        "        # end for\n",
        "\n",
        "        if showSteps == True: # show steps ###################################################\n",
        "            imgContours = np.zeros((height, width, 3), np.uint8)\n",
        "\n",
        "            for listOfMatchingChars in listOfListsOfMatchingCharsInPlate:\n",
        "                intRandomBlue = random.randint(0, 255)\n",
        "                intRandomGreen = random.randint(0, 255)\n",
        "                intRandomRed = random.randint(0, 255)\n",
        "\n",
        "                del contours[:]\n",
        "\n",
        "                for matchingChar in listOfMatchingChars:\n",
        "                    contours.append(matchingChar.contour)\n",
        "                # end for\n",
        "\n",
        "                cv2.drawContours(imgContours, contours, -1, (intRandomBlue, intRandomGreen, intRandomRed))\n",
        "            # end for\n",
        "            imgContours = Image.fromarray(imgContours,'RGB')\n",
        "            imgContours.show()\n",
        "#             input('Press Enter to Continue....')\n",
        "        # end if # show steps #####################################################################\n",
        "\n",
        "                # within each possible plate, suppose the longest list of potential matching chars is the actual list of chars\n",
        "        intLenOfLongestListOfChars = 0\n",
        "        intIndexOfLongestListOfChars = 0\n",
        "\n",
        "                # loop through all the vectors of matching chars, get the index of the one with the most chars\n",
        "        for i in range(0, len(listOfListsOfMatchingCharsInPlate)):\n",
        "            if len(listOfListsOfMatchingCharsInPlate[i]) > intLenOfLongestListOfChars:\n",
        "                intLenOfLongestListOfChars = len(listOfListsOfMatchingCharsInPlate[i])\n",
        "                intIndexOfLongestListOfChars = i\n",
        "            # end if\n",
        "        # end for\n",
        "\n",
        "                # suppose that the longest list of matching chars within the plate is the actual list of chars\n",
        "        longestListOfMatchingCharsInPlate = listOfListsOfMatchingCharsInPlate[intIndexOfLongestListOfChars]\n",
        "\n",
        "        if showSteps == True: # show steps ###################################################\n",
        "            imgContours = np.zeros((height, width, 3), np.uint8)\n",
        "            del contours[:]\n",
        "\n",
        "            for matchingChar in longestListOfMatchingCharsInPlate:\n",
        "                contours.append(matchingChar.contour)\n",
        "            # end for\n",
        "\n",
        "            cv2.drawContours(imgContours, contours, -1, SCALAR_WHITE)\n",
        "            imgContours = Image.fromarray(imgContours,'RGB')\n",
        "            imgContours.show()\n",
        "            \n",
        "            #cv2.imshow(\"The_Longest_list_of_matching_chars\", imgContours)\n",
        "            #cv2.waitKey(0)\n",
        "        # end if # show steps #####################################################################\n",
        "\n",
        "        possiblePlate.strChars = recognizeCharsInPlate(possiblePlate.imgThresh, longestListOfMatchingCharsInPlate)\n",
        "        #print('this character is recognized :',possiblePlate.strChars)\n",
        "        listOfPossiblePlates_refined.append(possiblePlate)\n",
        "\n",
        "        if showSteps == True: # show steps ###################################################\n",
        "            print(\"chars found in plate number \" + str(intPlateCounter) + \" = \" + possiblePlate.strChars + \", . . .\")\n",
        "            intPlateCounter = intPlateCounter + 1\n",
        "        # end if # show steps #####################################################################\n",
        "\n",
        "    # end of big for loop that takes up most of the function\n",
        "\n",
        "    if showSteps == True:\n",
        "        print(\"\\nchar detection complete, . . .\")\n",
        "    # end if\n",
        "    return listOfPossiblePlates_refined # we return the list of plates with the probable plate number of each plate.\n",
        "\n",
        "###################################################################################################\n",
        "def findPossibleCharsInPlate(imgGrayscale, imgThresh):\n",
        "    listOfPossibleChars = []                        # this will be the return value\n",
        "    contours = []\n",
        "    imgThreshCopy = imgThresh.copy()\n",
        "\n",
        "            # find all contours in plate\n",
        "    imgContours, contours, npaHierarchy = cv2.findContours(imgThreshCopy, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for contour in contours:                        # for each contour\n",
        "        possibleChar = PossibleChar(contour)\n",
        "\n",
        "        if checkIfPossibleChar(possibleChar):              # if contour is a possible char, note this does not compare to other chars (yet) . . .\n",
        "            listOfPossibleChars.append(possibleChar)       # add to list of possible chars\n",
        "        # end if\n",
        "    # end if\n",
        "\n",
        "    return listOfPossibleChars\n",
        "# end function\n",
        "\n",
        "###################################################################################################\n",
        "def checkIfPossibleChar(possibleChar):\n",
        "            # this function is a 'first pass' that does a rough check on a contour to see if it could be a char,\n",
        "            # note that we are not (yet) comparing the char to other chars to look for a group\n",
        "    if (possibleChar.intBoundingRectArea > MIN_PIXEL_AREA and\n",
        "        possibleChar.intBoundingRectWidth > MIN_PIXEL_WIDTH and possibleChar.intBoundingRectHeight > MIN_PIXEL_HEIGHT and\n",
        "        MIN_ASPECT_RATIO < possibleChar.fltAspectRatio and possibleChar.fltAspectRatio < MAX_ASPECT_RATIO):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "###################################################################################################\n",
        "def findListOfListsOfMatchingChars(listOfPossibleChars):\n",
        "            # with this function, we start off with all the possible chars in one big list\n",
        "            # the purpose of this function is to re-arrange the one big list of chars into a list of lists of matching chars,\n",
        "            # note that chars that are not found to be in a group of matches do not need to be considered further\n",
        "    listOfListsOfMatchingChars = []                  # this will be the return value\n",
        "    #print(\"Now we check which contours are similar\")\n",
        "\n",
        "    for possibleChar in listOfPossibleChars:                        # for each possible char in the one big list of chars\n",
        "\n",
        "        #print('We are checking for :')\n",
        "        #imgContours = np.zeros((height, width, 3), np.uint8)\n",
        "        #cv2.drawContours(imgContours, possibleChar.contour, -1, SCALAR_WHITE)\n",
        "        #cv2.imshow(\"2b\", imgContours)\n",
        "        #cv2.waitKey(0)\n",
        "\n",
        "        listOfMatchingChars = findListOfMatchingChars(possibleChar, listOfPossibleChars)        # find all chars in the big list that match the current char\n",
        "        listOfMatchingChars.append(possibleChar)                # also add the current char to current possible list of matching chars\n",
        "        if len(listOfMatchingChars) < MIN_NUMBER_OF_MATCHING_CHARS:     # if current possible list of matching chars is not long enough to constitute a possible plate\n",
        "            #print('Now a plate is complete')\n",
        "            continue\n",
        "        listOfListsOfMatchingChars.append(listOfMatchingChars)\n",
        "        listOfPossibleCharsWithCurrentMatchesRemoved = list(set(listOfPossibleChars) - set(listOfMatchingChars))\n",
        "        recursiveListOfListsOfMatchingChars = findListOfListsOfMatchingChars(listOfPossibleCharsWithCurrentMatchesRemoved)      # recursive call\n",
        "        for recursiveListOfMatchingChars in recursiveListOfListsOfMatchingChars:        # for each list of matching chars found by recursive call\n",
        "            listOfListsOfMatchingChars.append(recursiveListOfMatchingChars)\n",
        "        break;\n",
        "\n",
        "\n",
        "\n",
        "    return listOfListsOfMatchingChars\n",
        "# end function\n",
        "\n",
        "###################################################################################################\n",
        "def findListOfMatchingChars(possibleChar, listOfChars):\n",
        "            # the purpose of this function is, given a possible char and a big list of possible chars,\n",
        "            # find all chars in the big list that are a match for the single possible char, and return those matching chars as a list\n",
        "    listOfMatchingChars = []                # this will be the return value\n",
        "\n",
        "    for possibleMatchingChar in listOfChars:                # for each char in big list\n",
        "        if possibleMatchingChar == possibleChar:    # if the char we attempting to find matches for is the exact same char\n",
        "                                                    # as the char in the big list we are currently checking\n",
        "                                                    # then we should not include it in the list of matches b/c that would\n",
        "                                                    # end up double including the current char\n",
        "            continue                                # so do not add to list of matches and jump back to top of for loop\n",
        "        # end if\n",
        "                    # compute stuff to see if chars are a match\n",
        "        fltDistanceBetweenChars = distanceBetweenChars(possibleChar, possibleMatchingChar)\n",
        "\n",
        "        fltAngleBetweenChars = angleBetweenChars(possibleChar, possibleMatchingChar)\n",
        "\n",
        "        fltChangeInArea = float(abs(possibleMatchingChar.intBoundingRectArea - possibleChar.intBoundingRectArea)) / float(possibleChar.intBoundingRectArea)\n",
        "\n",
        "        fltChangeInWidth = float(abs(possibleMatchingChar.intBoundingRectWidth - possibleChar.intBoundingRectWidth)) / float(possibleChar.intBoundingRectWidth)\n",
        "        fltChangeInHeight = float(abs(possibleMatchingChar.intBoundingRectHeight - possibleChar.intBoundingRectHeight)) / float(possibleChar.intBoundingRectHeight)\n",
        "\n",
        "                # check if chars match\n",
        "        if (fltDistanceBetweenChars < (possibleChar.fltDiagonalSize * MAX_DIAG_SIZE_MULTIPLE_AWAY) and\n",
        "            fltAngleBetweenChars < MAX_ANGLE_BETWEEN_CHARS and\n",
        "            fltChangeInArea < MAX_CHANGE_IN_AREA and\n",
        "            fltChangeInWidth < MAX_CHANGE_IN_WIDTH and\n",
        "            fltChangeInHeight < MAX_CHANGE_IN_HEIGHT):\n",
        "\n",
        "            listOfMatchingChars.append(possibleMatchingChar)        # if the chars are a match, add the current char to list of matching chars\n",
        "            #print(\"\\t This contour is same:\")\n",
        "            #cv2.drawContours(imgContours, possibleMatchingChar.contour, -1, SCALAR_WHITE)\n",
        "            #cv2.imshow(\"2b\", imgContours)\n",
        "            #cv2.waitKey(0)\n",
        "        # end if\n",
        "    # end for\n",
        "\n",
        "    return listOfMatchingChars                  # return result\n",
        "# end function\n",
        "\n",
        "# use Pythagorean theorem to calculate distance between two chars\n",
        "def distanceBetweenChars(firstChar, secondChar):\n",
        "    intX = abs(firstChar.intCenterX - secondChar.intCenterX)\n",
        "    intY = abs(firstChar.intCenterY - secondChar.intCenterY)\n",
        "\n",
        "    return math.sqrt((intX ** 2) + (intY ** 2))\n",
        "\n",
        "# use basic trigonometry (SOH CAH TOA) to calculate angle between chars\n",
        "def angleBetweenChars(firstChar, secondChar):\n",
        "    fltAdj = float(abs(firstChar.intCenterX - secondChar.intCenterX))\n",
        "    fltOpp = float(abs(firstChar.intCenterY - secondChar.intCenterY))\n",
        "\n",
        "    if fltAdj != 0.0:                           # check to make sure we do not divide by zero if the center X positions are equal, float division by zero will cause a crash in Python\n",
        "        fltAngleInRad = math.atan(fltOpp / fltAdj)      # if adjacent is not zero, calculate angle\n",
        "    else:\n",
        "        fltAngleInRad = 1.5708                          # if adjacent is zero, use this as the angle, this is to be consistent with the C++ version of this program\n",
        "    # end if\n",
        "\n",
        "    fltAngleInDeg = fltAngleInRad * (180.0 / math.pi)       # calculate angle in degrees\n",
        "\n",
        "    return fltAngleInDeg\n",
        "# end function\n",
        "###################################################################################################\n",
        "\n",
        "# if we have two chars overlapping or to close to each other to possibly be separate chars, remove the inner (smaller) char,\n",
        "# this is to prevent including the same char twice if two contours are found for the same char,\n",
        "# for example for the letter 'O' both the inner ring and the outer ring may be found as contours, but we should only include the char once\n",
        "def removeInnerOverlappingChars(listOfMatchingChars):\n",
        "    listOfMatchingCharsWithInnerCharRemoved = list(listOfMatchingChars)                # this will be the return value\n",
        "\n",
        "    for currentChar in listOfMatchingChars:\n",
        "        for otherChar in listOfMatchingChars:\n",
        "            if currentChar != otherChar:        # if current char and other char are not the same char . . .\n",
        "                                                                            # if current char and other char have center points at almost the same location . . .\n",
        "                if distanceBetweenChars(currentChar, otherChar) < (currentChar.fltDiagonalSize * MIN_DIAG_SIZE_MULTIPLE_AWAY):\n",
        "                                # if we get in here we have found overlapping chars\n",
        "                                # next we identify which char is smaller, then if that char was not already removed on a previous pass, remove it\n",
        "                    if currentChar.intBoundingRectArea < otherChar.intBoundingRectArea:         # if current char is smaller than other char\n",
        "                        if currentChar in listOfMatchingCharsWithInnerCharRemoved:              # if current char was not already removed on a previous pass . . .\n",
        "                            listOfMatchingCharsWithInnerCharRemoved.remove(currentChar)         # then remove current char\n",
        "                        # end if\n",
        "                    else:                                                                       # else if other char is smaller than current char\n",
        "                        if otherChar in listOfMatchingCharsWithInnerCharRemoved:                # if other char was not already removed on a previous pass . . .\n",
        "                            listOfMatchingCharsWithInnerCharRemoved.remove(otherChar)           # then remove other char\n",
        "                        # end if\n",
        "                    # end if\n",
        "                # end if\n",
        "            # end if\n",
        "        # end for\n",
        "    # end for\n",
        "\n",
        "    return listOfMatchingCharsWithInnerCharRemoved\n",
        "# end function\n",
        "\n",
        "###################################################################################################\n",
        "# this is where we apply the actual char recognition\n",
        "def recognizeCharsInPlate(imgThresh, listOfMatchingChars):\n",
        "    strChars = \"\"               # this will be the return value, the chars in the lic plate\n",
        "\n",
        "    height, width = imgThresh.shape\n",
        "    imgThreshColor = np.zeros((height, width, 3), np.uint8)\n",
        "    #imgThresh = cv2.cvtColor(imgThresh, cv2.COLOR_BGR2HSV)\n",
        "    #imgHue, imgSaturation, imgThresh = cv2.split(imgHSV)\n",
        "    #cv2.threshold(possiblePlate.imgThresh, 0.0, 255.0, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "    #imgThreshColor = imgThresh.copy()\n",
        "    #imgThreshColor = cv2.resize(imgThreshColor, (0, 0), fx = 1.6, fy = 1.6)\n",
        "    thresholdValue, imgThresh = cv2.threshold(imgThresh, 0.0, 255.0, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    #imgThresh = cv2.fastNlMeansDenoising(imgThresh,None,10,10,7,21)\n",
        "    cv2.cvtColor(imgThresh, cv2.COLOR_GRAY2BGR, imgThreshColor)\n",
        "    #cv2.imshow('The Image',imgThreshColor)\n",
        "    #cv2.waitKey(0)\n",
        "    imgThreshColor2 = imgThreshColor.copy()\n",
        "    #cv2.imshow('The Plate',imgThreshColor2)\n",
        "    #cv2.waitKey(0)\n",
        "    listOfMatchingChars.sort(key = lambda matchingChar: matchingChar.intCenterX)        # sort chars from left to right\n",
        "\n",
        "    for currentChar in listOfMatchingChars:                                         # for each char in plate\n",
        "        pt1 = (currentChar.intBoundingRectX, currentChar.intBoundingRectY)\n",
        "        pt2 = ((currentChar.intBoundingRectX + currentChar.intBoundingRectWidth), (currentChar.intBoundingRectY + currentChar.intBoundingRectHeight))\n",
        "\n",
        "        cv2.rectangle(imgThreshColor2, pt1, pt2, (255,0,0), 2)           # draw green box around the char\n",
        "                # crop char out of threshold image\n",
        "        imgROI = imgThreshColor[currentChar.intBoundingRectY : currentChar.intBoundingRectY + currentChar.intBoundingRectHeight,currentChar.intBoundingRectX : currentChar.intBoundingRectX + currentChar.intBoundingRectWidth]\n",
        "        imgROI = cv2.copyMakeBorder(imgROI,8,8,8,8,cv2.BORDER_CONSTANT,value = [255,255,255])\n",
        "\n",
        "                # crop char out of threshold image    \n",
        "        #Image.fromarray(imgROI,'RGB').show()\n",
        "        #input('Press Enter to Continue....')\n",
        "        imgROIResized = cv2.resize(imgROI, (RESIZED_CHAR_IMAGE_WIDTH, RESIZED_CHAR_IMAGE_HEIGHT),interpolation=cv2.INTER_LINEAR)           # resize image, this is necessary for char recognition\n",
        "        #print('The shape is :',imgROIResized.shape)\n",
        "        #Image.fromarray(imgROI,'RGB').show()\n",
        "        #input('Press Enter to Continue....')\n",
        "        \"\"\"\n",
        "        response = str(input('Want to save the image: '))\n",
        "        if response == 'Y':\n",
        "            name = str(input('Enter the name: '))\n",
        "            cv2.imwrite(name, imgROIResized)\n",
        "        \"\"\"\n",
        "        img=np.reshape(imgROIResized,[1,64,64,3])\n",
        "\n",
        "        classes=model.predict_classes(img)\n",
        "        if classes[0]<10:\n",
        "            strCurrentChar = chr(classes[0]+48) # get character from results\n",
        "        else:\n",
        "            strCurrentChar = chr(classes[0]+55)    # get character from results\n",
        "        if showSteps == True:\n",
        "        \tprint(strCurrentChar)\n",
        "        strChars = strChars + strCurrentChar                        # append current char to full string\n",
        "\n",
        "\n",
        "    # end for\n",
        "\n",
        "    if showSteps == True: # show steps #######################################################\n",
        "        imgThreshColor2 = Image.fromarray(imgThreshColor2,'RGB')\n",
        "        imgThreshColor2.show()\n",
        "#         input('Press Enter to Continue....')\n",
        "    # end if # show steps #########################################################################\n",
        "\n",
        "    return strChars\n",
        "# end function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRYPO3jFV2TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DetectPlates.py\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# module level variables ##########################################################################\n",
        "PLATE_WIDTH_PADDING_FACTOR = 1.3\n",
        "PLATE_HEIGHT_PADDING_FACTOR = 1.5\n",
        "\n",
        "###################################################################################################\n",
        "def detectPlatesInScene(imgOriginalScene):\n",
        "    listOfPossiblePlates = []                   # this will be the return value\n",
        "\n",
        "    height, width, numChannels = imgOriginalScene.shape\n",
        "\n",
        "    imgGrayscaleScene = np.zeros((height, width, 1), np.uint8)\n",
        "    imgThreshScene = np.zeros((height, width, 1), np.uint8)\n",
        "    imgContours = np.zeros((height, width, 3), np.uint8)\n",
        "\n",
        "    if showSteps == True: # show steps #######################################################\n",
        "        #cv2.imshow(\"0\", imgOriginalScene)\n",
        "        Image.fromarray(imgOriginalScene).show()\n",
        "#         input('Press any key to continue...')\n",
        "        \n",
        "    imgGrayscaleScene, imgThreshScene = preprocess(imgOriginalScene)         # preprocess to get grayscale and threshold images\n",
        "\n",
        "            # find all possible chars in the scene,\n",
        "            # this function first finds all contours, then only includes contours that could be chars (without comparison to other chars yet)\n",
        "    listOfPossibleCharsInScene = findPossibleCharsInScene(imgThreshScene) # Here we get a list of all the contours in the image that may be characters.\n",
        "    \n",
        "\n",
        "    if showSteps == True: # show steps #######################################################\n",
        "        #print(\"step 2 - len(listOfPossibleCharsInScene) = \" + str(len(listOfPossibleCharsInScene)))\n",
        "\n",
        "        imgContours = np.zeros((height, width, 3), np.uint8)\n",
        "\n",
        "        contours = []\n",
        "\n",
        "        for possibleChar in listOfPossibleCharsInScene:\n",
        "            contours.append(possibleChar.contour)\n",
        "\n",
        "        cv2.drawContours(imgContours, contours, -1, SCALAR_WHITE)\n",
        "        Image.fromarray(imgOriginalScene).show()\n",
        "#         input('Press any key to continue...')\n",
        "        # This is for the boxing of all the contours\n",
        "        \"\"\"\n",
        "        for possibleChar in listOfPossibleCharsInScene:\n",
        "            cv2.rectangle(imgContours,(possibleChar.intBoundingRectX,possibleChar.intBoundingRectY),(possibleChar.intBoundingRectX+possibleChar.intBoundingRectWidth,possibleChar.intBoundingRectY+possibleChar.intBoundingRectHeight),(0.0, 255.0, 255.0),1)\n",
        "            cv2.imshow('PossiblePlate',imgContours)\n",
        "            cv2.waitKey(0)\n",
        "\n",
        "        \"\"\"\n",
        "            # given a list of all possible chars, find groups of matching chars\n",
        "            # in the next steps each group of matching chars will attempt to be recognized as a plate\n",
        "    listOfListsOfMatchingCharsInScene = findListOfListsOfMatchingChars(listOfPossibleCharsInScene)\n",
        "    if showSteps == True: # show steps #######################################################\n",
        "        print(\"step 3 - listOfListsOfMatchingCharsInScene.Count = \" + str(len(listOfListsOfMatchingCharsInScene)))    # 13 with MCLRNF1 image\n",
        "\n",
        "        imgContours = np.zeros((height, width, 3), np.uint8)\n",
        "\n",
        "        for listOfMatchingChars in listOfListsOfMatchingCharsInScene:\n",
        "            intRandomBlue = random.randint(0, 255)\n",
        "            intRandomGreen = random.randint(0, 255)\n",
        "            intRandomRed = random.randint(0, 255)\n",
        "\n",
        "            #imgContours2 = np.zeros((height, width, 3), np.uint8)\n",
        "\n",
        "            contours = []\n",
        "\n",
        "            for matchingChar in listOfMatchingChars:\n",
        "                contours.append(matchingChar.contour)\n",
        "            # end for\n",
        "\n",
        "            #cv2.drawContours(imgContours, contours, -1, (255, 255, 255))\n",
        "            cv2.drawContours(imgContours, contours, -1, (intRandomBlue, intRandomGreen, intRandomRed))\n",
        "        # end for\n",
        "            \n",
        "            #imgContours = Image.fromarray(imgContours,'RGB').show()\n",
        "            \n",
        "        \n",
        "    # end if # show steps #########################################################################\n",
        "    for listOfMatchingChars in listOfListsOfMatchingCharsInScene:                   # for each group of matching chars\n",
        "        possiblePlate = extractPlate(imgOriginalScene, listOfMatchingChars)         # attempt to extract plate\n",
        "\n",
        "        if possiblePlate.imgPlate is not None:                          # if plate was found\n",
        "            listOfPossiblePlates.append(possiblePlate)                  # add to list of possible plates\n",
        "            \n",
        "\n",
        "    if showSteps == True:\n",
        "      pass\n",
        "#         print(\"\\n\" + str(len(listOfPossiblePlates)) + \" possible plates found\")\n",
        "  \n",
        "    if showSteps == True: # show steps #######################################################\n",
        "#         print(\"\\n\")\n",
        "        \n",
        "        Image.fromarray(imgContours,'RGB').show()\n",
        "#         input('Press any key to continue...')\n",
        "        for i in range(0, len(listOfPossiblePlates)):\n",
        "            p2fRectPoints = cv2.boxPoints(listOfPossiblePlates[i].rrLocationOfPlateInScene)\n",
        "\n",
        "            cv2.line(imgContours, tuple(p2fRectPoints[0]), tuple(p2fRectPoints[1]), SCALAR_RED, 2)\n",
        "            cv2.line(imgContours, tuple(p2fRectPoints[1]), tuple(p2fRectPoints[2]), SCALAR_RED, 2)\n",
        "            cv2.line(imgContours, tuple(p2fRectPoints[2]), tuple(p2fRectPoints[3]), SCALAR_RED, 2)\n",
        "            cv2.line(imgContours, tuple(p2fRectPoints[3]), tuple(p2fRectPoints[0]), SCALAR_RED, 2)\n",
        "\n",
        "            #cv2.imshow(\"4a\", imgContours)\n",
        "            \n",
        "#             print(\"possible plate \" + str(i) + \", click on any image and press a key to continue . . .\")\n",
        "            #Image.fromarray(listOfPossiblePlates[i].imgPlate,'RGB').show()\n",
        "            \n",
        "        # end for\n",
        "#         print(\"\\nplate detection complete, press a key to begin char recognition . . .\\n\")\n",
        "#         input()\n",
        "    # end if # show steps #########################################################################\n",
        "    \n",
        "    return listOfPossiblePlates\n",
        "\n",
        "###################################################################################################\n",
        "def findPossibleCharsInScene(imgThresh):\n",
        "    listOfPossibleChars = []                # this will be the return value\n",
        "\n",
        "    intCountOfPossibleChars = 0\n",
        "\n",
        "    imgThreshCopy = imgThresh.copy()\n",
        "    #print('Now we start to find the contours in the thresholded image that may be characters:')\n",
        "\n",
        "    imgContours, contours, npaHierarchy = cv2.findContours(imgThreshCopy, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)   # find all contours\n",
        "\n",
        "    height, width = imgThresh.shape\n",
        "    imgContours = np.zeros((height, width, 3), np.uint8)\n",
        "\n",
        "    for i in range(0, len(contours)):                       # for each contour\n",
        "\n",
        "        if showSteps == True: # show steps ###################################################\n",
        "            cv2.drawContours(imgContours, contours, i, SCALAR_YELLOW)\n",
        "            #Image.fromarray(imgContours,'RGB').show()\n",
        "            \n",
        "        possibleChar = PossibleChar(contours[i]) # Here we calculate the x,y,w,h,flatdiagonalsize,aspedctratio,area and (x,y) of the center of the rectangle that is bounding the contour.\n",
        "\n",
        "        if checkIfPossibleChar(possibleChar):                   # if contour is a possible char, note this does not compare to other chars (yet) . . .\n",
        "            intCountOfPossibleChars = intCountOfPossibleChars + 1           # increment count of possible chars\n",
        "            listOfPossibleChars.append(possibleChar)                        # and add to list of possible chars\n",
        "            #cv2.drawContours(imgContours, contours, i, SCALAR_WHITE)\n",
        "            #print('This contour may be a character :')\n",
        "        #else:\n",
        "            #print('This contour is not a character :')\n",
        "        # end if\n",
        "    # end for\n",
        "\n",
        "    if showSteps == True: # show steps #######################################################\n",
        "        print(\"\\nstep 2 - Total number of contours found in the image are = \" + str(len(contours)))\n",
        "        print(\"step 2 - number of contours those may be characters = \" + str(intCountOfPossibleChars))\n",
        "        #print(\"These are the contours those may be characters :\")\n",
        "        Image.fromarray(imgContours,'RGB').show()\n",
        "    # end if # show steps #########################################################################\n",
        "\n",
        "    return listOfPossibleChars\n",
        "\n",
        "###################################################################################################\n",
        "def extractPlate(imgOriginal, listOfMatchingChars):\n",
        "    possiblePlate = PossiblePlate()           # this will be the return value\n",
        "\n",
        "    listOfMatchingChars.sort(key = lambda matchingChar: matchingChar.intCenterX)        # sort chars from left to right based on x position\n",
        "\n",
        "            # calculate the center point of the plate\n",
        "    fltPlateCenterX = (listOfMatchingChars[0].intCenterX + listOfMatchingChars[len(listOfMatchingChars) - 1].intCenterX) / 2.0\n",
        "    fltPlateCenterY = (listOfMatchingChars[0].intCenterY + listOfMatchingChars[len(listOfMatchingChars) - 1].intCenterY) / 2.0\n",
        "    # This is the probable centeral point of this plate.\n",
        "    ptPlateCenter = fltPlateCenterX, fltPlateCenterY\n",
        "\n",
        "            # calculate plate width and height\n",
        "    intPlateWidth = int((listOfMatchingChars[len(listOfMatchingChars) - 1].intBoundingRectX + listOfMatchingChars[len(listOfMatchingChars) - 1].intBoundingRectWidth - listOfMatchingChars[0].intBoundingRectX) * PLATE_WIDTH_PADDING_FACTOR)\n",
        "    # Here we calculate the probable width of this plate.\n",
        "    intTotalOfCharHeights = 0\n",
        "\n",
        "    for matchingChar in listOfMatchingChars:\n",
        "        intTotalOfCharHeights = intTotalOfCharHeights + matchingChar.intBoundingRectHeight\n",
        "\n",
        "    fltAverageCharHeight = intTotalOfCharHeights / len(listOfMatchingChars) # Here we calculate the probale height of this particular plate.\n",
        "\n",
        "    intPlateHeight = int(fltAverageCharHeight * PLATE_HEIGHT_PADDING_FACTOR) # We include the padding factor.\n",
        "\n",
        "            # calculate correction angle of plate region\n",
        "    fltOpposite = listOfMatchingChars[len(listOfMatchingChars) - 1].intCenterY - listOfMatchingChars[0].intCenterY\n",
        "    fltHypotenuse = distanceBetweenChars(listOfMatchingChars[0], listOfMatchingChars[len(listOfMatchingChars) - 1])\n",
        "    fltCorrectionAngleInRad = math.asin(fltOpposite / fltHypotenuse)\n",
        "    fltCorrectionAngleInDeg = fltCorrectionAngleInRad * (180.0 / math.pi)\n",
        "\n",
        "            # pack plate region center point, width and height, and correction angle into rotated rect member variable of plate\n",
        "    possiblePlate.rrLocationOfPlateInScene = ( tuple(ptPlateCenter), (intPlateWidth, intPlateHeight), fltCorrectionAngleInDeg )\n",
        "\n",
        "            # final steps are to perform the actual rotation\n",
        "\n",
        "            # get the rotation matrix for our calculated correction angle\n",
        "    rotationMatrix = cv2.getRotationMatrix2D(tuple(ptPlateCenter), fltCorrectionAngleInDeg, 1.0) # The first poin tis the point of rotaion or center,theta and scaling factor\n",
        "\n",
        "\n",
        "    height, width, numChannels = imgOriginal.shape      # unpack original image width and height\n",
        "\n",
        "    imgRotated = cv2.warpAffine(imgOriginal, rotationMatrix, (width, height))       # rotate the entire image\n",
        "\n",
        "    imgCropped = cv2.getRectSubPix(imgRotated, (intPlateWidth, intPlateHeight), tuple(ptPlateCenter)) # We extract the probable plate from the Original image\n",
        "\n",
        "    possiblePlate.imgPlate = imgCropped         # copy the cropped plate image into the applicable member variable of the possible plate\n",
        "\n",
        "    return possiblePlate\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0_x9OdyW6PW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "SCALAR_BLACK = (0.0, 0.0, 0.0)\n",
        "SCALAR_WHITE = (255.0, 255.0, 255.0)\n",
        "SCALAR_YELLOW = (0.0, 255.0, 255.0)\n",
        "SCALAR_GREEN = (0.0, 255.0, 0.0)\n",
        "SCALAR_RED = (0.0, 0.0, 255.0)\n",
        "\n",
        "showSteps = True\n",
        "\n",
        "def main(image):\n",
        "\n",
        "    CnnClassifier = loadCNNClassifier()         # attempt KNN training\n",
        "    #response  = str(input('Do you want to see the Intermediate images: '))\n",
        "    \"\"\"\n",
        "    if response == 'Y' or response == 'y':\n",
        "        showSteps = True\n",
        "    else:\n",
        "        showSteps = False\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if CnnClassifier == False:                               # if KNN training was not successful\n",
        "        print(\"\\nerror: CNN traning was not successful\\n\")               # show error message\n",
        "        return                                                          # and exit program\n",
        "\n",
        "    imgOriginalScene  = cv2.imread(image)               # open image\n",
        "    #plt.imshow(imgOriginalScene)\n",
        "    h, w = imgOriginalScene.shape[:2]\n",
        "    # As the image may be blurr so we sharpen the image.\n",
        "    #kernel_shapening4 = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
        "    #imgOriginalScene = cv2.filter2D(imgOriginalScene,-1,kernel_shapening4)\n",
        "    \n",
        "    #imgOriginalScene = cv2.resize(imgOriginalScene,(1000,600),interpolation = cv2.INTER_LINEAR)\n",
        "    \n",
        "    imgOriginalScene = cv2.resize(imgOriginalScene, (0, 0), fx = 1.4, fy = 1.4,interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    #imgOriginalScene = cv2.fastNlMeansDenoisingColored(imgOriginalScene,None,10,10,7,21)\n",
        "    \n",
        "    #imgOriginal = imgOriginalScene.copy()\n",
        "    \n",
        "    if imgOriginalScene is None:                            # if image was not read successfully\n",
        "        print(\"\\nerror: image not read from file \\n\\n\")      # print error message to std out\n",
        "        os.system(\"pause\")                                  # pause so user can see error message\n",
        "        return                                              # and exit program\n",
        "\n",
        "    listOfPossiblePlates = detectPlatesInScene(imgOriginalScene)           # detect plates. We get a list of\n",
        "                                                                                        # combinations of contours that may be a plate.\n",
        "\n",
        "\n",
        "    listOfPossiblePlates = detectCharsInPlates(listOfPossiblePlates)        # detect chars in plates\n",
        "\n",
        "    if showSteps == True:\n",
        "        Image.fromarray(imgOriginalScene,'RGB').show() # show scene image\n",
        "        \n",
        "\n",
        "    if len(listOfPossiblePlates) == 0:                          # if no plates were found\n",
        "        print(\"\\nno license plates were detected\\n\")             # inform user no plates were found\n",
        "        response = ' '\n",
        "        return response,imgOriginalScene\n",
        "    else:                                                       # else\n",
        "                # if we get in here list of possible plates has at leat one plate\n",
        "\n",
        "                # sort the list of possible plates in DESCENDING order (most number of chars to least number of chars)\n",
        "        listOfPossiblePlates.sort(key = lambda possiblePlate: len(possiblePlate.strChars), reverse = True)\n",
        "\n",
        "                # suppose the plate with the most recognized chars (the first plate in sorted by string length descending order) is the actual plate\n",
        "        licPlate = listOfPossiblePlates[0]\n",
        "\n",
        "        if showSteps == True:\n",
        "            Image.fromarray(licPlate.imgPlate).show()    # show crop of plate and threshold of plate\n",
        "            \n",
        "        if len(licPlate.strChars) == 0:                     # if no chars were found in the plate\n",
        "            print(\"\\nno characters were detected\\n\\n\")       # show message\n",
        "            return ' ',imgOriginalScene                                       # and exit program\n",
        "        # end if\n",
        "\n",
        "        drawRedRectangleAroundPlate(imgOriginalScene, licPlate)             # draw red rectangle around plate\n",
        "        \"\"\"\n",
        "\t\t# Uncomment this if want to check for individual plate\n",
        "        print(\"\\nlicense plate read from \", image,\" :\",licPlate.strChars,\"\\n\")\n",
        "        print(\"----------------------------------------\")\n",
        "\t\t\"\"\"\n",
        "        if showSteps == True:\n",
        "            writeLicensePlateCharsOnImage(imgOriginalScene, licPlate)           # write license plate text on the image\n",
        "\n",
        "            Image.fromarray(imgOriginalScene).show()                # re-show scene image\n",
        "\n",
        "            cv2.imwrite(\"imgOriginalScene.png\", imgOriginalScene)           # write image out to file\n",
        "#             input('Press any key to continue...')                    # hold windows open until user presses a key\n",
        "\n",
        "    return licPlate.strChars,licPlate.imgPlate\n",
        "###################################################################################################\n",
        "def drawRedRectangleAroundPlate(imgOriginalScene, licPlate):\n",
        "\n",
        "    p2fRectPoints = cv2.boxPoints(licPlate.rrLocationOfPlateInScene)            # get 4 vertices of rotated rect. Here, bounding rectangle is drawn with minimum area, so it considers the rotation also\n",
        "\n",
        "    cv2.line(imgOriginalScene, tuple(p2fRectPoints[0]), tuple(p2fRectPoints[1]), SCALAR_RED, 2)         # draw 4 red lines\n",
        "    cv2.line(imgOriginalScene, tuple(p2fRectPoints[1]), tuple(p2fRectPoints[2]), SCALAR_RED, 2)\n",
        "    cv2.line(imgOriginalScene, tuple(p2fRectPoints[2]), tuple(p2fRectPoints[3]), SCALAR_RED, 2)\n",
        "    cv2.line(imgOriginalScene, tuple(p2fRectPoints[3]), tuple(p2fRectPoints[0]), SCALAR_RED, 2)\n",
        "# end function\n",
        "\n",
        "###################################################################################################\n",
        "def writeLicensePlateCharsOnImage(imgOriginalScene, licPlate):\n",
        "    ptCenterOfTextAreaX = 0                             # this will be the center of the area the text will be written to\n",
        "    ptCenterOfTextAreaY = 0\n",
        "\n",
        "    ptLowerLeftTextOriginX = 0                          # this will be the bottom left of the area that the text will be written to\n",
        "    ptLowerLeftTextOriginY = 0\n",
        "\n",
        "    sceneHeight, sceneWidth, sceneNumChannels = imgOriginalScene.shape\n",
        "    plateHeight, plateWidth, plateNumChannels = licPlate.imgPlate.shape\n",
        "\n",
        "    intFontFace = cv2.FONT_HERSHEY_SIMPLEX                      # choose a plain jane font\n",
        "    fltFontScale = float(plateHeight) / 30.0                    # base font scale on height of plate area\n",
        "    intFontThickness = int(round(fltFontScale * 1.5))           # base font thickness on font scale\n",
        "\n",
        "    textSize, baseline = cv2.getTextSize(licPlate.strChars, intFontFace, fltFontScale, intFontThickness)        # call getTextSize\n",
        "\n",
        "            # unpack roatated rect into center point, width and height, and angle\n",
        "    ( (intPlateCenterX, intPlateCenterY), (intPlateWidth, intPlateHeight), fltCorrectionAngleInDeg ) = licPlate.rrLocationOfPlateInScene\n",
        "\n",
        "    intPlateCenterX = int(intPlateCenterX)              # make sure center is an integer\n",
        "    intPlateCenterY = int(intPlateCenterY)\n",
        "\n",
        "    ptCenterOfTextAreaX = int(intPlateCenterX)         # the horizontal location of the text area is the same as the plate\n",
        "\n",
        "    if intPlateCenterY < (sceneHeight * 0.75):                                                  # if the license plate is in the upper 3/4 of the image\n",
        "        ptCenterOfTextAreaY = int(round(intPlateCenterY)) + int(round(plateHeight * 1.6))      # write the chars in below the plate\n",
        "    else:                                                                                       # else if the license plate is in the lower 1/4 of the image\n",
        "        ptCenterOfTextAreaY = int(round(intPlateCenterY)) - int(round(plateHeight * 1.6))      # write the chars in above the plate\n",
        "    # end if\n",
        "\n",
        "    textSizeWidth, textSizeHeight = textSize                # unpack text size width and height\n",
        "\n",
        "    ptLowerLeftTextOriginX = int(ptCenterOfTextAreaX - (textSizeWidth / 2))           # calculate the lower left origin of the text area\n",
        "    ptLowerLeftTextOriginY = int(ptCenterOfTextAreaY + (textSizeHeight / 2))          # based on the text area center, width, and height\n",
        "\n",
        "            # write the text on the image\n",
        "    cv2.putText(imgOriginalScene, licPlate.strChars, (ptLowerLeftTextOriginX, ptLowerLeftTextOriginY), intFontFace, fltFontScale, SCALAR_YELLOW, intFontThickness)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqqX0hG3XFQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "62dec5e4-c489-4f46-82d2-238fc9136d92"
      },
      "source": [
        "strChars,imgplate = main('/content/drive/My Drive/Vehicle_Licenseplate_Detection/Datasets/LicPlateImages/img1.jpg')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "step 2 - Total number of contours found in the image are = 816\n",
            "step 2 - number of contours those may be characters = 50\n",
            "step 3 - listOfListsOfMatchingCharsInScene.Count = 3\n",
            "D\n",
            "L\n",
            "1\n",
            "0\n",
            "C\n",
            "T\n",
            "5\n",
            "8\n",
            "0\n",
            "S\n",
            "chars found in plate number 0 = DL10CT580S, . . .\n",
            "chars found in plate number 1 = (none), click on any image and press a key to continue . . .\n",
            "D\n",
            "L\n",
            "1\n",
            "0\n",
            "C\n",
            "T\n",
            "5\n",
            "8\n",
            "0\n",
            "6\n",
            "chars found in plate number 2 = DL10CT5806, . . .\n",
            "\n",
            "char detection complete, . . .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhE-wuIiXQ-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44e3321e-0152-4298-a1a4-1b637a90e145"
      },
      "source": [
        "strChars"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DL10CT580S'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyqH5VpMd8JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}