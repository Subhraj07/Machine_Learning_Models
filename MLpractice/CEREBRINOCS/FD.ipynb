{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subhraj07/Machine_Learning_Models/blob/master/MLpractice/CEREBRINOCS/FD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzdwq4mGuiE_",
        "colab_type": "text"
      },
      "source": [
        "https://chamaradodandeniya.wordpress.com/2019/04/16/how-to-configure-google-colab-for-object-detection-using-tensorflow/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29LWFCbYtSh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "4eaf95d0-b9c2-4e81-ad1f-b15f78df64ab"
      },
      "source": [
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        " \n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "   \n",
        "sess = tf.Session(config=config)\n",
        " \n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print('ok')\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0801 10:29:33.559412 139667805661056 deprecation.py:323] From <ipython-input-4-5d5135f72728>:7: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "W0801 10:29:33.568605 139667805661056 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gng45AiCukV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "e5b6881d-f095-4c62-a6b2-ab904f1377d3"
      },
      "source": [
        "from os.path import join\n",
        "from google.colab import drive\n",
        " \n",
        "ROOT = \"/content/drive\"\n",
        "drive.mount(ROOT)\n",
        " \n",
        "PROJ = \"My Drive/TF_Model\" # This is a custom path.\n",
        "PROJECT_PATH = join(ROOT, PROJ)\n",
        " \n",
        "%cd ~/content\n",
        "%cd drive/My Drive/TF_Model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: '/root/content'\n",
            "/content\n",
            "/content/drive/My Drive/TF_Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8o868iiu1UX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "7ee0a1af-b599-4f11-90dc-ca31f01e8fed"
      },
      "source": [
        "!git clone https://github.com/dodandeniya/TFmodels.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TFmodels'...\n",
            "remote: Enumerating objects: 557, done.\u001b[K\n",
            "remote: Counting objects: 100% (557/557), done.\u001b[K\n",
            "remote: Compressing objects: 100% (379/379), done.\u001b[K\n",
            "remote: Total 557 (delta 171), reused 547 (delta 170), pack-reused 0\n",
            "Receiving objects: 100% (557/557), 107.63 MiB | 21.73 MiB/s, done.\n",
            "Resolving deltas: 100% (171/171), done.\n",
            "Checking out files: 100% (533/533), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L61rBN-EvKuK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "41cf1151-0d65-4799-d3ae-3df871df8139"
      },
      "source": [
        "%cd ~\n",
        "%cd /content\n",
        "%cd drive/My Drive/TF_Model/TFmodels/research\n",
        "!pwd\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content\n",
            "/content/drive/My Drive/TF_Model/TFmodels/research\n",
            "/content/drive/My Drive/TF_Model/TFmodels/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPdQI8K1viGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "74787cb5-279d-4fe6-f312-7025099f2c71"
      },
      "source": [
        "%cd ~\n",
        "%cd /content\n",
        "%cd drive/My Drive/TF_Model/\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/My Drive/TF_Model/TFmodels/research/:/content/drive/My Drive/TF_Model/TFmodels/research/slim/'\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/My Drive/TF_Model/TFmodels/research/:/content/drive/My Drive/TF_Model/TFmodels/research/object_detection/'\n",
        "!python TFmodels/research/object_detection/builders/model_builder_test.py\n",
        " \n",
        "# Change the directory path\n",
        " \n",
        "%cd TFmodels/research/object_detection"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content\n",
            "/content/drive/My Drive/TF_Model\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0801 10:37:49.429499 140450016061312 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0801 10:37:50.159146 140450016061312 deprecation_wrapper.py:119] From /content/drive/My Drive/TF_Model/TFmodels/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0801 10:37:50.417732 140450016061312 deprecation_wrapper.py:119] From /content/drive/My Drive/TF_Model/TFmodels/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Running tests under Python 3.6.8: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 16 tests in 0.076s\n",
            "\n",
            "OK (skipped=1)\n",
            "/content/drive/My Drive/TF_Model/TFmodels/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akmYDElRxUOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from numpy import genfromtxt\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "_FLOATX = 'float32'\n",
        "\n",
        "def variable(value, dtype=_FLOATX, name=None):\n",
        "  v = tf.Variable(np.asarray(value, dtype=dtype), name=name)\n",
        "  _get_session().run(v.initializer)\n",
        "  return v\n",
        "\n",
        "def shape(x):\n",
        "  return x.get_shape()\n",
        "\n",
        "def square(x):\n",
        "  return tf.square(x)\n",
        "\n",
        "def zeros(shape, dtype=_FLOATX, name=None):\n",
        "  return variable(np.zeros(shape), dtype, name)\n",
        "\n",
        "def concatenate(tensors, axis=-1):\n",
        "  if axis < 0:\n",
        "      axis = axis % len(tensors[0].get_shape())\n",
        "  return tf.concat(axis, tensors)\n",
        "\n",
        "def LRN2D(x):\n",
        "  return tf.nn.lrn(x, alpha=1e-4, beta=0.75)\n",
        "\n",
        "def conv2d_bn(\n",
        "  x,\n",
        "  layer=None,\n",
        "  cv1_out=None,\n",
        "  cv1_filter=(1, 1),\n",
        "  cv1_strides=(1, 1),\n",
        "  cv2_out=None,\n",
        "  cv2_filter=(3, 3),\n",
        "  cv2_strides=(1, 1),\n",
        "  padding=None,\n",
        "):\n",
        "  num = '' if cv2_out == None else '1'\n",
        "  tensor = Conv2D(cv1_out, cv1_filter, strides=cv1_strides, name=layer+'_conv'+num)(x)\n",
        "  tensor = BatchNormalization(axis=3, epsilon=0.00001, name=layer+'_bn'+num)(tensor)\n",
        "  tensor = Activation('relu')(tensor)\n",
        "  if padding == None:\n",
        "    return tensor\n",
        "  tensor = ZeroPadding2D(padding=padding)(tensor)\n",
        "  if cv2_out == None:\n",
        "    return tensor\n",
        "  tensor = Conv2D(cv2_out, cv2_filter, strides=cv2_strides, name=layer+'_conv'+'2')(tensor)\n",
        "  tensor = BatchNormalization(axis=3, epsilon=0.00001, name=layer+'_bn'+'2')(tensor)\n",
        "  tensor = Activation('relu')(tensor)\n",
        "  return tensor\n",
        "\n",
        "weights = [\n",
        "  'conv1', 'bn1', 'conv2', 'bn2', 'conv3', 'bn3',\n",
        "  'inception_3a_1x1_conv', 'inception_3a_1x1_bn',\n",
        "  'inception_3a_pool_conv', 'inception_3a_pool_bn',\n",
        "  'inception_3a_5x5_conv1', 'inception_3a_5x5_conv2', 'inception_3a_5x5_bn1', 'inception_3a_5x5_bn2',\n",
        "  'inception_3a_3x3_conv1', 'inception_3a_3x3_conv2', 'inception_3a_3x3_bn1', 'inception_3a_3x3_bn2',\n",
        "  'inception_3b_3x3_conv1', 'inception_3b_3x3_conv2', 'inception_3b_3x3_bn1', 'inception_3b_3x3_bn2',\n",
        "  'inception_3b_5x5_conv1', 'inception_3b_5x5_conv2', 'inception_3b_5x5_bn1', 'inception_3b_5x5_bn2',\n",
        "  'inception_3b_pool_conv', 'inception_3b_pool_bn',\n",
        "  'inception_3b_1x1_conv', 'inception_3b_1x1_bn',\n",
        "  'inception_3c_3x3_conv1', 'inception_3c_3x3_conv2', 'inception_3c_3x3_bn1', 'inception_3c_3x3_bn2',\n",
        "  'inception_3c_5x5_conv1', 'inception_3c_5x5_conv2', 'inception_3c_5x5_bn1', 'inception_3c_5x5_bn2',\n",
        "  'inception_4a_3x3_conv1', 'inception_4a_3x3_conv2', 'inception_4a_3x3_bn1', 'inception_4a_3x3_bn2',\n",
        "  'inception_4a_5x5_conv1', 'inception_4a_5x5_conv2', 'inception_4a_5x5_bn1', 'inception_4a_5x5_bn2',\n",
        "  'inception_4a_pool_conv', 'inception_4a_pool_bn',\n",
        "  'inception_4a_1x1_conv', 'inception_4a_1x1_bn',\n",
        "  'inception_4e_3x3_conv1', 'inception_4e_3x3_conv2', 'inception_4e_3x3_bn1', 'inception_4e_3x3_bn2',\n",
        "  'inception_4e_5x5_conv1', 'inception_4e_5x5_conv2', 'inception_4e_5x5_bn1', 'inception_4e_5x5_bn2',\n",
        "  'inception_5a_3x3_conv1', 'inception_5a_3x3_conv2', 'inception_5a_3x3_bn1', 'inception_5a_3x3_bn2',\n",
        "  'inception_5a_pool_conv', 'inception_5a_pool_bn',\n",
        "  'inception_5a_1x1_conv', 'inception_5a_1x1_bn',\n",
        "  'inception_5b_3x3_conv1', 'inception_5b_3x3_conv2', 'inception_5b_3x3_bn1', 'inception_5b_3x3_bn2',\n",
        "  'inception_5b_pool_conv', 'inception_5b_pool_bn',\n",
        "  'inception_5b_1x1_conv', 'inception_5b_1x1_bn',\n",
        "  'dense_layer'\n",
        "]\n",
        "\n",
        "conv_shape = {\n",
        "  'conv1': [64, 3, 7, 7],\n",
        "  'conv2': [64, 64, 1, 1],\n",
        "  'conv3': [192, 64, 3, 3],\n",
        "  'inception_3a_1x1_conv': [64, 192, 1, 1],\n",
        "  'inception_3a_pool_conv': [32, 192, 1, 1],\n",
        "  'inception_3a_5x5_conv1': [16, 192, 1, 1],\n",
        "  'inception_3a_5x5_conv2': [32, 16, 5, 5],\n",
        "  'inception_3a_3x3_conv1': [96, 192, 1, 1],\n",
        "  'inception_3a_3x3_conv2': [128, 96, 3, 3],\n",
        "  'inception_3b_3x3_conv1': [96, 256, 1, 1],\n",
        "  'inception_3b_3x3_conv2': [128, 96, 3, 3],\n",
        "  'inception_3b_5x5_conv1': [32, 256, 1, 1],\n",
        "  'inception_3b_5x5_conv2': [64, 32, 5, 5],\n",
        "  'inception_3b_pool_conv': [64, 256, 1, 1],\n",
        "  'inception_3b_1x1_conv': [64, 256, 1, 1],\n",
        "  'inception_3c_3x3_conv1': [128, 320, 1, 1],\n",
        "  'inception_3c_3x3_conv2': [256, 128, 3, 3],\n",
        "  'inception_3c_5x5_conv1': [32, 320, 1, 1],\n",
        "  'inception_3c_5x5_conv2': [64, 32, 5, 5],\n",
        "  'inception_4a_3x3_conv1': [96, 640, 1, 1],\n",
        "  'inception_4a_3x3_conv2': [192, 96, 3, 3],\n",
        "  'inception_4a_5x5_conv1': [32, 640, 1, 1,],\n",
        "  'inception_4a_5x5_conv2': [64, 32, 5, 5],\n",
        "  'inception_4a_pool_conv': [128, 640, 1, 1],\n",
        "  'inception_4a_1x1_conv': [256, 640, 1, 1],\n",
        "  'inception_4e_3x3_conv1': [160, 640, 1, 1],\n",
        "  'inception_4e_3x3_conv2': [256, 160, 3, 3],\n",
        "  'inception_4e_5x5_conv1': [64, 640, 1, 1],\n",
        "  'inception_4e_5x5_conv2': [128, 64, 5, 5],\n",
        "  'inception_5a_3x3_conv1': [96, 1024, 1, 1],\n",
        "  'inception_5a_3x3_conv2': [384, 96, 3, 3],\n",
        "  'inception_5a_pool_conv': [96, 1024, 1, 1],\n",
        "  'inception_5a_1x1_conv': [256, 1024, 1, 1],\n",
        "  'inception_5b_3x3_conv1': [96, 736, 1, 1],\n",
        "  'inception_5b_3x3_conv2': [384, 96, 3, 3],\n",
        "  'inception_5b_pool_conv': [96, 736, 1, 1],\n",
        "  'inception_5b_1x1_conv': [256, 736, 1, 1],\n",
        "}\n",
        "\n",
        "def load_weights():\n",
        "  weightsDir = './weights'\n",
        "  fileNames = filter(lambda f: not f.startswith('.'), os.listdir(weightsDir))\n",
        "  paths = {}\n",
        "  weights_dict = {}\n",
        "\n",
        "  for n in fileNames:\n",
        "    paths[n.replace('.csv', '')] = weightsDir + '/' + n\n",
        "\n",
        "  for name in weights:\n",
        "    if 'conv' in name:\n",
        "      conv_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
        "      conv_w = np.reshape(conv_w, conv_shape[name])\n",
        "      conv_w = np.transpose(conv_w, (2, 3, 1, 0))\n",
        "      conv_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
        "      weights_dict[name] = [conv_w, conv_b]     \n",
        "    elif 'bn' in name:\n",
        "      bn_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
        "      bn_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
        "      bn_m = genfromtxt(paths[name + '_m'], delimiter=',', dtype=None)\n",
        "      bn_v = genfromtxt(paths[name + '_v'], delimiter=',', dtype=None)\n",
        "      weights_dict[name] = [bn_w, bn_b, bn_m, bn_v]\n",
        "    elif 'dense' in name:\n",
        "      dense_w = genfromtxt(weightsDir+'/dense_w.csv', delimiter=',', dtype=None)\n",
        "      dense_w = np.reshape(dense_w, (128, 736))\n",
        "      dense_w = np.transpose(dense_w, (1, 0))\n",
        "      dense_b = genfromtxt(weightsDir+'/dense_b.csv', delimiter=',', dtype=None)\n",
        "      weights_dict[name] = [dense_w, dense_b]\n",
        "\n",
        "  return weights_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxEC2642wbT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------\n",
        "# Code taken from https://github.com/iwantooxxoox/Keras-OpenFace (with minor modifications)\n",
        "# -----------------------------------------------------------------------------------------\n",
        "\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "import utils\n",
        "\n",
        "def create_model():\n",
        "    myInput = Input(shape=(96, 96, 3))\n",
        "\n",
        "    x = ZeroPadding2D(padding=(3, 3), input_shape=(96, 96, 3))(myInput)\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
        "    x = BatchNormalization(axis=3, epsilon=0.00001, name='bn1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
        "    x = Lambda(LRN2D, name='lrn_1')(x)\n",
        "    x = Conv2D(64, (1, 1), name='conv2')(x)\n",
        "    x = BatchNormalization(axis=3, epsilon=0.00001, name='bn2')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = Conv2D(192, (3, 3), name='conv3')(x)\n",
        "    x = BatchNormalization(axis=3, epsilon=0.00001, name='bn3')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Lambda(LRN2D, name='lrn_2')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
        "\n",
        "    # Inception3a\n",
        "    inception_3a_3x3 = Conv2D(96, (1, 1), name='inception_3a_3x3_conv1')(x)\n",
        "    inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn1')(inception_3a_3x3)\n",
        "    inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
        "    inception_3a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3)\n",
        "    inception_3a_3x3 = Conv2D(128, (3, 3), name='inception_3a_3x3_conv2')(inception_3a_3x3)\n",
        "    inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn2')(inception_3a_3x3)\n",
        "    inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
        "\n",
        "    inception_3a_5x5 = Conv2D(16, (1, 1), name='inception_3a_5x5_conv1')(x)\n",
        "    inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn1')(inception_3a_5x5)\n",
        "    inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
        "    inception_3a_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5)\n",
        "    inception_3a_5x5 = Conv2D(32, (5, 5), name='inception_3a_5x5_conv2')(inception_3a_5x5)\n",
        "    inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn2')(inception_3a_5x5)\n",
        "    inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
        "\n",
        "    inception_3a_pool = MaxPooling2D(pool_size=3, strides=2)(x)\n",
        "    inception_3a_pool = Conv2D(32, (1, 1), name='inception_3a_pool_conv')(inception_3a_pool)\n",
        "    inception_3a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_pool_bn')(inception_3a_pool)\n",
        "    inception_3a_pool = Activation('relu')(inception_3a_pool)\n",
        "    inception_3a_pool = ZeroPadding2D(padding=((3, 4), (3, 4)))(inception_3a_pool)\n",
        "\n",
        "    inception_3a_1x1 = Conv2D(64, (1, 1), name='inception_3a_1x1_conv')(x)\n",
        "    inception_3a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_1x1_bn')(inception_3a_1x1)\n",
        "    inception_3a_1x1 = Activation('relu')(inception_3a_1x1)\n",
        "\n",
        "    inception_3a = concatenate([inception_3a_3x3, inception_3a_5x5, inception_3a_pool, inception_3a_1x1], axis=3)\n",
        "\n",
        "    # Inception3b\n",
        "    inception_3b_3x3 = Conv2D(96, (1, 1), name='inception_3b_3x3_conv1')(inception_3a)\n",
        "    inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn1')(inception_3b_3x3)\n",
        "    inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
        "    inception_3b_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3)\n",
        "    inception_3b_3x3 = Conv2D(128, (3, 3), name='inception_3b_3x3_conv2')(inception_3b_3x3)\n",
        "    inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn2')(inception_3b_3x3)\n",
        "    inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
        "\n",
        "    inception_3b_5x5 = Conv2D(32, (1, 1), name='inception_3b_5x5_conv1')(inception_3a)\n",
        "    inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn1')(inception_3b_5x5)\n",
        "    inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
        "    inception_3b_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5)\n",
        "    inception_3b_5x5 = Conv2D(64, (5, 5), name='inception_3b_5x5_conv2')(inception_3b_5x5)\n",
        "    inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn2')(inception_3b_5x5)\n",
        "    inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
        "\n",
        "    inception_3b_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_3a)\n",
        "    inception_3b_pool = Conv2D(64, (1, 1), name='inception_3b_pool_conv')(inception_3b_pool)\n",
        "    inception_3b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_pool_bn')(inception_3b_pool)\n",
        "    inception_3b_pool = Activation('relu')(inception_3b_pool)\n",
        "    inception_3b_pool = ZeroPadding2D(padding=(4, 4))(inception_3b_pool)\n",
        "\n",
        "    inception_3b_1x1 = Conv2D(64, (1, 1), name='inception_3b_1x1_conv')(inception_3a)\n",
        "    inception_3b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_1x1_bn')(inception_3b_1x1)\n",
        "    inception_3b_1x1 = Activation('relu')(inception_3b_1x1)\n",
        "\n",
        "    inception_3b = concatenate([inception_3b_3x3, inception_3b_5x5, inception_3b_pool, inception_3b_1x1], axis=3)\n",
        "\n",
        "    # Inception3c\n",
        "    inception_3c_3x3 = utils.conv2d_bn(inception_3b,\n",
        "                                       layer='inception_3c_3x3',\n",
        "                                       cv1_out=128,\n",
        "                                       cv1_filter=(1, 1),\n",
        "                                       cv2_out=256,\n",
        "                                       cv2_filter=(3, 3),\n",
        "                                       cv2_strides=(2, 2),\n",
        "                                       padding=(1, 1))\n",
        "\n",
        "    inception_3c_5x5 = utils.conv2d_bn(inception_3b,\n",
        "                                       layer='inception_3c_5x5',\n",
        "                                       cv1_out=32,\n",
        "                                       cv1_filter=(1, 1),\n",
        "                                       cv2_out=64,\n",
        "                                       cv2_filter=(5, 5),\n",
        "                                       cv2_strides=(2, 2),\n",
        "                                       padding=(2, 2))\n",
        "\n",
        "    inception_3c_pool = MaxPooling2D(pool_size=3, strides=2)(inception_3b)\n",
        "    inception_3c_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_3c_pool)\n",
        "\n",
        "    inception_3c = concatenate([inception_3c_3x3, inception_3c_5x5, inception_3c_pool], axis=3)\n",
        "\n",
        "    #inception 4a\n",
        "    inception_4a_3x3 = utils.conv2d_bn(inception_3c,\n",
        "                                       layer='inception_4a_3x3',\n",
        "                                       cv1_out=96,\n",
        "                                       cv1_filter=(1, 1),\n",
        "                                       cv2_out=192,\n",
        "                                       cv2_filter=(3, 3),\n",
        "                                       cv2_strides=(1, 1),\n",
        "                                       padding=(1, 1))\n",
        "    inception_4a_5x5 = utils.conv2d_bn(inception_3c,\n",
        "                                       layer='inception_4a_5x5',\n",
        "                                       cv1_out=32,\n",
        "                                       cv1_filter=(1, 1),\n",
        "                                       cv2_out=64,\n",
        "                                       cv2_filter=(5, 5),\n",
        "                                       cv2_strides=(1, 1),\n",
        "                                       padding=(2, 2))\n",
        "\n",
        "    inception_4a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_3c)\n",
        "    inception_4a_pool = utils.conv2d_bn(inception_4a_pool,\n",
        "                                        layer='inception_4a_pool',\n",
        "                                        cv1_out=128,\n",
        "                                        cv1_filter=(1, 1),\n",
        "                                        padding=(2, 2))\n",
        "    inception_4a_1x1 = utils.conv2d_bn(inception_3c,\n",
        "                                       layer='inception_4a_1x1',\n",
        "                                       cv1_out=256,\n",
        "                                       cv1_filter=(1, 1))\n",
        "    inception_4a = concatenate([inception_4a_3x3, inception_4a_5x5, inception_4a_pool, inception_4a_1x1], axis=3)\n",
        "\n",
        "    #inception4e\n",
        "    inception_4e_3x3 = utils.conv2d_bn(inception_4a,\n",
        "                                       layer='inception_4e_3x3',\n",
        "                                       cv1_out=160,\n",
        "                                       cv1_filter=(1, 1),\n",
        "                                       cv2_out=256,\n",
        "                                       cv2_filter=(3, 3),\n",
        "                                       cv2_strides=(2, 2),\n",
        "                                       padding=(1, 1))\n",
        "    inception_4e_5x5 = utils.conv2d_bn(inception_4a,\n",
        "                                       layer='inception_4e_5x5',\n",
        "                                       cv1_out=64,\n",
        "                                       cv1_filter=(1, 1),\n",
        "                                       cv2_out=128,\n",
        "                                       cv2_filter=(5, 5),\n",
        "                                       cv2_strides=(2, 2),\n",
        "                                       padding=(2, 2))\n",
        "    inception_4e_pool = MaxPooling2D(pool_size=3, strides=2)(inception_4a)\n",
        "    inception_4e_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_4e_pool)\n",
        "\n",
        "    inception_4e = concatenate([inception_4e_3x3, inception_4e_5x5, inception_4e_pool], axis=3)\n",
        "\n",
        "    #inception5a\n",
        "    inception_5a_3x3 = utils.conv2d_bn(inception_4e,\n",
        "                                       layer='inception_5a_3x3',\n",
        "                                       cv1_out=96,\n",
        "                                       cv1_filter=(1, 1),\n",
        "                                       cv2_out=384,\n",
        "                                       cv2_filter=(3, 3),\n",
        "                                       cv2_strides=(1, 1),\n",
        "                                       padding=(1, 1))\n",
        "\n",
        "    inception_5a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_4e)\n",
        "    inception_5a_pool = utils.conv2d_bn(inception_5a_pool,\n",
        "                                        layer='inception_5a_pool',\n",
        "                                        cv1_out=96,\n",
        "                                        cv1_filter=(1, 1),\n",
        "                                        padding=(1, 1))\n",
        "    inception_5a_1x1 = utils.conv2d_bn(inception_4e,\n",
        "                                       layer='inception_5a_1x1',\n",
        "                                       cv1_out=256,\n",
        "                                       cv1_filter=(1, 1))\n",
        "\n",
        "    inception_5a = concatenate([inception_5a_3x3, inception_5a_pool, inception_5a_1x1], axis=3)\n",
        "\n",
        "    #inception_5b\n",
        "    inception_5b_3x3 = utils.conv2d_bn(inception_5a,\n",
        "                                       layer='inception_5b_3x3',\n",
        "                                       cv1_out=96,\n",
        "                                       cv1_filter=(1, 1),\n",
        "                                       cv2_out=384,\n",
        "                                       cv2_filter=(3, 3),\n",
        "                                       cv2_strides=(1, 1),\n",
        "                                       padding=(1, 1))\n",
        "    inception_5b_pool = MaxPooling2D(pool_size=3, strides=2)(inception_5a)\n",
        "    inception_5b_pool = utils.conv2d_bn(inception_5b_pool,\n",
        "                                        layer='inception_5b_pool',\n",
        "                                        cv1_out=96,\n",
        "                                        cv1_filter=(1, 1))\n",
        "    inception_5b_pool = ZeroPadding2D(padding=(1, 1))(inception_5b_pool)\n",
        "\n",
        "    inception_5b_1x1 = utils.conv2d_bn(inception_5a,\n",
        "                                       layer='inception_5b_1x1',\n",
        "                                       cv1_out=256,\n",
        "                                       cv1_filter=(1, 1))\n",
        "    inception_5b = concatenate([inception_5b_3x3, inception_5b_pool, inception_5b_1x1], axis=3)\n",
        "\n",
        "    av_pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1))(inception_5b)\n",
        "    reshape_layer = Flatten()(av_pool)\n",
        "    dense_layer = Dense(128, name='dense_layer')(reshape_layer)\n",
        "    norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n",
        "\n",
        "    return Model(inputs=[myInput], outputs=norm_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGgsC8QExo4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "842fa869-e57c-4b48-9c04-5693714eec43"
      },
      "source": [
        "%cd ~\n",
        "%cd /content"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kz3lx54wmpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bz2\n",
        "import os\n",
        "\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def download_landmarks(dst_file):\n",
        "    url = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'\n",
        "    decompressor = bz2.BZ2Decompressor()\n",
        "    \n",
        "    with urlopen(url) as src, open(dst_file, 'wb') as dst:\n",
        "        data = src.read(1024)\n",
        "        while len(data) > 0:\n",
        "            dst.write(decompressor.decompress(data))\n",
        "            data = src.read(1024)\n",
        "\n",
        "dst_dir = 'models'\n",
        "dst_file = os.path.join(dst_dir, 'landmarks.dat')\n",
        "\n",
        "if not os.path.exists(dst_file):\n",
        "    os.makedirs(dst_dir)\n",
        "    download_landmarks(dst_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS6jm_ghxers",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "db3a3843-6d46-4b59-a3b7-00ca399807b5"
      },
      "source": [
        "nn4_small2 = create_model()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0801 10:43:44.277778 139667805661056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0801 10:43:44.279755 139667805661056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0801 10:43:44.293677 139667805661056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0801 10:43:44.322503 139667805661056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0801 10:43:44.323423 139667805661056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0801 10:43:44.378674 139667805661056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0801 10:43:44.443330 139667805661056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0801 10:43:45.554038 139667805661056 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-40608ec92c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn4_small2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-3789e221159b>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Inception3c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     inception_3c_3x3 = utils.conv2d_bn(inception_3b,\n\u001b[0m\u001b[1;32m     92\u001b[0m                                        \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inception_3c_3x3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                                        \u001b[0mcv1_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'utils' has no attribute 'conv2d_bn'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ui4Ol3WxxNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}